{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>  Классификация твитов. Базанов Дмитрий Б03-903 </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (14640, 15)\n"
     ]
    }
   ],
   "source": [
    "raw_data = pd.read_csv('Tweets.csv')\n",
    "print('shape:', raw_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:48 -0800</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "0  570306133677760513           neutral                        1.0000   \n",
       "1  570301130888122368          positive                        0.3486   \n",
       "2  570301083672813571           neutral                        0.6837   \n",
       "\n",
       "  negativereason  negativereason_confidence         airline  \\\n",
       "0            NaN                        NaN  Virgin America   \n",
       "1            NaN                        0.0  Virgin America   \n",
       "2            NaN                        NaN  Virgin America   \n",
       "\n",
       "  airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n",
       "0                    NaN     cairdin                 NaN              0   \n",
       "1                    NaN    jnardino                 NaN              0   \n",
       "2                    NaN  yvonnalynn                 NaN              0   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0                @VirginAmerica What @dhepburn said.         NaN   \n",
       "1  @VirginAmerica plus you've added commercials t...         NaN   \n",
       "2  @VirginAmerica I didn't today... Must mean I n...         NaN   \n",
       "\n",
       "               tweet_created tweet_location               user_timezone  \n",
       "0  2015-02-24 11:35:52 -0800            NaN  Eastern Time (US & Canada)  \n",
       "1  2015-02-24 11:15:59 -0800            NaN  Pacific Time (US & Canada)  \n",
       "2  2015-02-24 11:15:48 -0800      Lets Play  Central Time (US & Canada)  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выделим уникальные названия компаний и юзернеймы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "usernames = raw_data['name'].apply(lambda x: x.lower()).unique()\n",
    "airlines = raw_data['airline'].apply(lambda x: x.lower()).unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сразу удалим признаки, которые нам не нужны для решения задачи по самим твитам\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = raw_data.drop(['tweet_location', 'user_timezone', 'tweet_coord', 'negativereason', 'name', 'retweet_count',\n",
    "                     'airline_sentiment_gold', 'negativereason_gold', 'tweet_created', 'tweet_id', 'airline'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline_sentiment  airline_sentiment_confidence  negativereason_confidence  \\\n",
       "0           neutral                        1.0000                        NaN   \n",
       "1          positive                        0.3486                     0.0000   \n",
       "2           neutral                        0.6837                        NaN   \n",
       "3          negative                        1.0000                     0.7033   \n",
       "4          negative                        1.0000                     1.0000   \n",
       "\n",
       "                                                text  \n",
       "0                @VirginAmerica What @dhepburn said.  \n",
       "1  @VirginAmerica plus you've added commercials t...  \n",
       "2  @VirginAmerica I didn't today... Must mean I n...  \n",
       "3  @VirginAmerica it's really aggressive to blast...  \n",
       "4  @VirginAmerica and it's a really big bad thing...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14640 entries, 0 to 14639\n",
      "Data columns (total 4 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   airline_sentiment             14640 non-null  object \n",
      " 1   airline_sentiment_confidence  14640 non-null  float64\n",
      " 2   negativereason_confidence     10522 non-null  float64\n",
      " 3   text                          14640 non-null  object \n",
      "dtypes: float64(2), object(2)\n",
      "memory usage: 457.6+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Препроцессинг:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данных есть пропуске в поле 'negativereason_confidence'. Рассмотрим, как распределён этот признак среди 'airline_sentiment'\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>0.933365</td>\n",
       "      <td>0.731769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>0.823303</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>0.872039</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   airline_sentiment_confidence  negativereason_confidence\n",
       "airline_sentiment                                                         \n",
       "negative                               0.933365                   0.731769\n",
       "neutral                                0.823303                   0.000000\n",
       "positive                               0.872039                   0.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('airline_sentiment').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что если отзыв положительный или нейтральный, то уверенность в негативности отзыва всегда равна нулю. Посмотрим, сколько негативных отзывов с пустым полем:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['negativereason_confidence', 'airline_sentiment']]\\\n",
    "[(data.negativereason_confidence.isnull()) & (data.airline_sentiment != 'negative')].dropna().shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "То есть все поля, которые соответствуют отрицательному отзыву, заполнены, а если средне значение положительных и нейтральных отзывов равно нулю, то мы можем заполнить все пустые значений нулями и не изменить среднее."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['negativereason_confidence'] = data['negativereason_confidence'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14640 entries, 0 to 14639\n",
      "Data columns (total 4 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   airline_sentiment             14640 non-null  object \n",
      " 1   airline_sentiment_confidence  14640 non-null  float64\n",
      " 2   negativereason_confidence     14640 non-null  float64\n",
      " 3   text                          14640 non-null  object \n",
      "dtypes: float64(2), object(2)\n",
      "memory usage: 457.6+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>0.933365</td>\n",
       "      <td>0.731769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>0.823303</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>0.872039</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   airline_sentiment_confidence  negativereason_confidence\n",
       "airline_sentiment                                                         \n",
       "negative                               0.933365                   0.731769\n",
       "neutral                                0.823303                   0.000000\n",
       "positive                               0.872039                   0.000000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('airline_sentiment').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь выделим целевой признак"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.replace({'airline_sentiment': {'positive': 1, 'negative': -1, 'neutral': 0}})['airline_sentiment']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    0\n",
       "3   -1\n",
       "4   -1\n",
       "Name: airline_sentiment, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                  @VirginAmerica What @dhepburn said.\n",
       "1    @VirginAmerica plus you've added commercials t...\n",
       "2    @VirginAmerica I didn't today... Must mean I n...\n",
       "3    @VirginAmerica it's really aggressive to blast...\n",
       "4    @VirginAmerica and it's a really big bad thing...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем функцию для обработки каждого отдельного твита на предмет Никнеймов и прочего ненужного шума"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_to_words(tweet):\n",
    "    tweet = re.sub(r'@\\w+', '', tweet)\n",
    "    letters = re.sub(\"[^a-zA-Z]\", \" \", tweet)\n",
    "    words = letters.lower().split()\n",
    "    words = [x for x in words if not x in airlines]\n",
    "    return (' '. join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['clean_tweet']=data['text'].apply(lambda x: tweet_to_words(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>what said</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>plus you ve added commercials to the experienc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>i didn t today must mean i need to take anothe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>it s really aggressive to blast obnoxious ente...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>and it s a really big bad thing about it</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline_sentiment  airline_sentiment_confidence  negativereason_confidence  \\\n",
       "0           neutral                        1.0000                     0.0000   \n",
       "1          positive                        0.3486                     0.0000   \n",
       "2           neutral                        0.6837                     0.0000   \n",
       "3          negative                        1.0000                     0.7033   \n",
       "4          negative                        1.0000                     1.0000   \n",
       "\n",
       "                                                text  \\\n",
       "0                @VirginAmerica What @dhepburn said.   \n",
       "1  @VirginAmerica plus you've added commercials t...   \n",
       "2  @VirginAmerica I didn't today... Must mean I n...   \n",
       "3  @VirginAmerica it's really aggressive to blast...   \n",
       "4  @VirginAmerica and it's a really big bad thing...   \n",
       "\n",
       "                                         clean_tweet  \n",
       "0                                          what said  \n",
       "1  plus you ve added commercials to the experienc...  \n",
       "2  i didn t today must mean i need to take anothe...  \n",
       "3  it s really aggressive to blast obnoxious ente...  \n",
       "4           and it s a really big bad thing about it  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Применим лемматизацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lem(tweet):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    word_list = nltk.word_tokenize(tweet)\n",
    "    lemmatized_output = ' '.join([lemmatizer.lemmatize(w) for w in word_list])\n",
    "    return(lemmatized_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применим для каждого твита:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['lem_clean_tweet']=data['clean_tweet'].apply(lambda x: lem(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>lem_clean_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what said</td>\n",
       "      <td>what said</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>plus you ve added commercials to the experienc...</td>\n",
       "      <td>plus you ve added commercial to the experience...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i didn t today must mean i need to take anothe...</td>\n",
       "      <td>i didn t today must mean i need to take anothe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>it s really aggressive to blast obnoxious ente...</td>\n",
       "      <td>it s really aggressive to blast obnoxious ente...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>and it s a really big bad thing about it</td>\n",
       "      <td>and it s a really big bad thing about it</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         clean_tweet  \\\n",
       "0                                          what said   \n",
       "1  plus you ve added commercials to the experienc...   \n",
       "2  i didn t today must mean i need to take anothe...   \n",
       "3  it s really aggressive to blast obnoxious ente...   \n",
       "4           and it s a really big bad thing about it   \n",
       "\n",
       "                                     lem_clean_tweet  \n",
       "0                                          what said  \n",
       "1  plus you ve added commercial to the experience...  \n",
       "2  i didn t today must mean i need to take anothe...  \n",
       "3  it s really aggressive to blast obnoxious ente...  \n",
       "4           and it s a really big bad thing about it  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['clean_tweet', 'lem_clean_tweet']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Так же применим стемминг:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(tweet):\n",
    "    porter = PorterStemmer()\n",
    "    word_list = nltk.word_tokenize(tweet)\n",
    "    porter_output = ' '.join([porter.stem(w) for w in word_list])\n",
    "    return(porter_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['stem_lem_clean_tweet']=data['lem_clean_tweet'].apply(lambda x: stem(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lem_clean_tweet</th>\n",
       "      <th>stem_lem_clean_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what said</td>\n",
       "      <td>what said</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>plus you ve added commercial to the experience...</td>\n",
       "      <td>plu you ve ad commerci to the experi tacki</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i didn t today must mean i need to take anothe...</td>\n",
       "      <td>i didn t today must mean i need to take anoth ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>it s really aggressive to blast obnoxious ente...</td>\n",
       "      <td>it s realli aggress to blast obnoxi entertain ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>and it s a really big bad thing about it</td>\n",
       "      <td>and it s a realli big bad thing about it</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     lem_clean_tweet  \\\n",
       "0                                          what said   \n",
       "1  plus you ve added commercial to the experience...   \n",
       "2  i didn t today must mean i need to take anothe...   \n",
       "3  it s really aggressive to blast obnoxious ente...   \n",
       "4           and it s a really big bad thing about it   \n",
       "\n",
       "                                stem_lem_clean_tweet  \n",
       "0                                          what said  \n",
       "1         plu you ve ad commerci to the experi tacki  \n",
       "2  i didn t today must mean i need to take anoth ...  \n",
       "3  it s realli aggress to blast obnoxi entertain ...  \n",
       "4           and it s a realli big bad thing about it  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['lem_clean_tweet', 'stem_lem_clean_tweet']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11712, 8705), (2928, 8705))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect = CountVectorizer(stop_words='english', analyzer='word')\n",
    "train_features = count_vect.fit_transform(train['stem_lem_clean_tweet'])\n",
    "test_features = count_vect.transform(test['stem_lem_clean_tweet'])\n",
    "train_features.shape, test_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подберём модель на данных после всего лемматизации и стемминга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, recall_score, accuracy_score, \\\n",
    "    precision_score, make_scorer, f1_score\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция для вывода всех нужных метрик:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scores(true, pred):\n",
    "    print('accuracy_score', round(accuracy_score(true, pred), 3))\n",
    "    print('roc_auc_score', round(roc_auc_score(true,\n",
    "        preds_proba, multi_class='ovr', average=\"weighted\"), 3))\n",
    "    print('recall_score', round(recall_score(true, pred, average=\"weighted\"), 3))\n",
    "    print('precision_score', round(precision_score(true, pred, average=\"weighted\"), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Параметры по умолчанию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= LogisticRegression =========\n",
      "accuracy_score 0.799\n",
      "roc_auc_score 0.899\n",
      "recall_score 0.799\n",
      "precision_score 0.794\n",
      "========= XGBClassifier =========\n",
      "accuracy_score 0.785\n",
      "roc_auc_score 0.89\n",
      "recall_score 0.785\n",
      "precision_score 0.776\n",
      "========= RandomForestClassifier =========\n",
      "accuracy_score 0.768\n",
      "roc_auc_score 0.871\n",
      "recall_score 0.768\n",
      "precision_score 0.759\n",
      "CPU times: user 37.9 s, sys: 19.1 s, total: 57 s\n",
      "Wall time: 17.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "models = [\n",
    "    LogisticRegression(random_state=42, max_iter=200),\n",
    "    xgb.XGBClassifier(random_state=42),\n",
    "    RandomForestClassifier(random_state=42)\n",
    "]\n",
    "\n",
    "for model in models:\n",
    "    model.fit(train_features, train['airline_sentiment'])\n",
    "    pred = model.predict(test_features)\n",
    "    preds_proba = model.predict_proba(test_features)\n",
    "    print('=========', model.__class__.__name__, '=========')\n",
    "    scores(test.airline_sentiment, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По сетке LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score 0.802\n",
      "roc_auc_score 0.871\n",
      "recall_score 0.802\n",
      "precision_score 0.796\n",
      "CPU times: user 11.7 s, sys: 12.3 s, total: 24 s\n",
      "Wall time: 19.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "params_lr = {\n",
    "    'max_iter': [200, 350, 500],\n",
    "    'C': [0.01, 0.5, 1.0],\n",
    "    \n",
    "}\n",
    "\n",
    "logregrGrid = GridSearchCV(LogisticRegression(random_state=42), params_lr, scoring=make_scorer(f1_score, average=\"weighted\"), n_jobs=-1)\n",
    "logregrGrid.fit(train_features, train['airline_sentiment'])\n",
    "scores(test['airline_sentiment'], logregrGrid.predict(test_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По сетке XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:   15.4s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   25.2s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   28.2s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   54.8s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done  69 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done  82 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done  97 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 129 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done 160 out of 160 | elapsed:  5.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score 0.795\n",
      "roc_auc_score 0.871\n",
      "recall_score 0.795\n",
      "precision_score 0.79\n",
      "CPU times: user 25.5 s, sys: 283 ms, total: 25.8 s\n",
      "Wall time: 5min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "params_xgb = {\n",
    "    'min_child_weight': [1, 5],\n",
    "    'gamma': [1, 2],\n",
    "    'subsample': [0.3, 0.7],\n",
    "    'eta': [0.1, 0.3],\n",
    "    'max_depth': [9, 15]\n",
    "}\n",
    "\n",
    "XGBGrid = GridSearchCV(xgb.XGBClassifier(random_state=42), params_xgb, \n",
    "                       scoring=make_scorer(f1_score, average=\"weighted\"), n_jobs=-1, verbose=10)\n",
    "XGBGrid.fit(train_features, train['airline_sentiment'])\n",
    "scores(test['airline_sentiment'], XGBGrid.predict(test_features))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По сетке RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    7.3s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   10.9s\n",
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed:   16.3s\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:   23.6s\n",
      "[Parallel(n_jobs=-1)]: Done  69 tasks      | elapsed:   30.7s\n",
      "[Parallel(n_jobs=-1)]: Done  82 tasks      | elapsed:   41.5s\n",
      "[Parallel(n_jobs=-1)]: Done  97 tasks      | elapsed:   51.3s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:   56.8s\n",
      "[Parallel(n_jobs=-1)]: Done 129 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 165 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed:  1.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score 0.645\n",
      "roc_auc_score 0.871\n",
      "recall_score 0.645\n",
      "precision_score 0.416\n",
      "CPU times: user 1.39 s, sys: 123 ms, total: 1.51 s\n",
      "Wall time: 1min 41s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zugzvangg/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "params_rf = {\n",
    "    'n_estimators': [200,300, 500],\n",
    "    'max_features': ['auto', 'sqrt'],\n",
    "    'max_depth': [2, 5, 10],\n",
    "    'criterion':['gini', 'entropy']\n",
    "}\n",
    "\n",
    "RFGrid = GridSearchCV(RandomForestClassifier(random_state=42), params_rf, \n",
    "                      scoring=make_scorer(f1_score, average=\"weighted\"), n_jobs=-1, verbose=10)\n",
    "RFGrid.fit(train_features, train['airline_sentiment'])\n",
    "scores(test['airline_sentiment'], RFGrid.predict(test_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучшие, довольно хорошие метрики, даёт логистическая регрессия. Поиск по сетке не очень значительно, но улучшает метрики. При использовании RandomForest без сетки, он на удивление хуже отрабатывает, нежели без сетки. В целом метрики выходят нормальными, если использовать XGBoost или Регрессию. RandomForest плохо подходит для этой задачи."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
